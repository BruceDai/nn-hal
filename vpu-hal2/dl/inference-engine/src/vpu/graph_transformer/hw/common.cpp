//
// INTEL CONFIDENTIAL
// Copyright 2018 Intel Corporation.
//
// The source code contained or described herein and all documents
// related to the source code ("Material") are owned by Intel Corporation
// or its suppliers or licensors. Title to the Material remains with
// Intel Corporation or its suppliers and licensors. The Material may
// contain trade secrets and proprietary and confidential information
// of Intel Corporation and its suppliers and licensors, and is protected
// by worldwide copyright and trade secret laws and treaty provisions.
// No part of the Material may be used, copied, reproduced, modified,
// published, uploaded, posted, transmitted, distributed, or disclosed
// in any way without Intel's prior express written permission.
//
// No license under any patent, copyright, trade secret or other
// intellectual property right is granted to or conferred upon you by
// disclosure or delivery of the Materials, either expressly, by implication,
// inducement, estoppel or otherwise. Any license under such intellectual
// property rights must be express and approved by Intel in writing.
//
// Include any supplier copyright notices as supplier requires Intel to use.
//
// Include supplier trademarks or logos as supplier requires Intel to use,
// preceded by an asterisk. An asterisked footnote can be added as follows:
// *Third Party trademarks are the property of their respective owners.
//
// Unless otherwise agreed by Intel in writing, you may not remove or alter
// this notice or any other notice embedded in Materials by Intel or Intel's
// suppliers or licensors in any way.
//

#include "common.hpp"
#include <tuple>
#include <vector>
#include <algorithm>
#include <limits>
#include <string>
#include <utility>

HwPaddingInfo getPadding(const VpuDims& inDims, const VpuDims& outDims,
                         uint32_t kernelDimX, uint32_t kernelDimY,
                         uint32_t kernelStrideX, uint32_t kernelStrideY) {
    uint32_t valid_out_x = std::ceil(static_cast<double>(inDims[Dim::X] - kernelDimX + 1) / kernelStrideX);
    uint32_t valid_out_y = std::ceil(static_cast<double>(inDims[Dim::Y] - kernelDimY + 1) / kernelStrideY);

    auto pad_along_x = (outDims[Dim::X] - 1) * kernelStrideX + kernelDimX - inDims[Dim::X];
    auto pad_along_y = (outDims[Dim::Y] - 1) * kernelStrideY + kernelDimY - inDims[Dim::Y];

    HwPaddingInfo pad;

    pad.left = pad_along_x / 2;
    pad.right = pad_along_x - pad.left;
    pad.top = pad_along_y / 2;
    pad.bottom = pad_along_y - pad.top;

    pad.enable = (outDims[Dim::X] != valid_out_x || outDims[Dim::Y] != valid_out_y);

    return pad;
}

namespace {

// Computes the output dimension (x or y) based on the input size, kernel size, stride and padding
int calcOutputSize(int inputSize, int kernelSize, int stride,
                   const std::tuple<int, int>& pad) {
    int padBefore, padAfter;
    std::tie(padBefore, padAfter) = pad;

    return (inputSize - kernelSize + padBefore + padAfter) / stride + 1;
}

// Note:
//
//   * [inputStartIndex, inputEndIndex): is the original range, without account for splits
//   * inputLinesBefore: specifies how many elements we need to remove from inputStartIndex to get the correct starting point
//   * junkOutputBefore: With starting point inputStartIndex - inputLinesBefore, this value contains the junk lines we need to discard
//   * [outputStartIndex, outputEndIndex): is the output range we are interested in generating, without the extra junk that might be there
//   * junkOutputBefore: is the junk contained before the outputStartIndex
//   * junkOutputAfter: is the junk contained after the outputEndIndex
//
// The output generated by the hardware is:
//
//   [outputStartIndex - junkOutputBefore, outputEndIndex + junkOutputAfter)
std::tuple<int, int, int, int, int, int, int, int>
    inputLinesForOutputLines(int inputSize, int kernelSize, int stride,
                             const std::tuple<int, int>& pad,
                             const std::tuple<int, int>& output) {
    int padBefore, padAfter;
    std::tie(padBefore, padAfter) = pad;

    int outputStartIndex, outputEndIndex;
    std::tie(outputStartIndex, outputEndIndex) = output;

    // Negative value encodes the padding
    int inputStartIndex = -padBefore + outputStartIndex * stride;
    int inputEndIndex = -padBefore + (outputEndIndex - 1) * stride + kernelSize;

    int inputLinesBefore = 0;
    int junkOutputBefore = 0;

    if (inputStartIndex < 0) {
        // Negative inputStartIndex means that we use the original padding

        inputLinesBefore = 0;
        inputStartIndex = 0;
        if (outputStartIndex == 0)
            junkOutputBefore = 0;
        else
            junkOutputBefore = outputStartIndex;
    } else {
        // Non-negative inputStartIndex means that we either have no padding, or we are in the middle of the image

        // We reduce the inputStartIndex to the smallest non-negative integer
        inputLinesBefore = inputStartIndex;
        while (inputLinesBefore >= stride)
            inputLinesBefore -= stride;

        // Compute the junkOutputBefore
        junkOutputBefore = (inputLinesBefore + padBefore) / stride;
    }

    int inputLinesAfter = 0;
    int junkOutputAfter = 0;

    if (inputEndIndex > inputSize) {
        // Larger inputEndIndex means that we use the original padding at the bottom of the image

        int paddingUsed = inputEndIndex - inputSize;

        inputLinesAfter = 0;
        inputEndIndex = inputSize;

        // The hardware will continue to compute output lines, until the kernel is just inside the padded image.
        junkOutputAfter = 0;
        while (paddingUsed + stride <= padAfter) {
            paddingUsed += stride;
            junkOutputAfter += 1;
        }
    } else {
        // This value of inputEndIndex means that we either have no padding, or we are in the middle of the image

        inputLinesAfter = 0;

        // Count how many kernels fit with the provided padding
        int paddingUsed = 0;
        junkOutputAfter = 0;
        while (paddingUsed + stride <= padAfter) {
            paddingUsed += stride;
            junkOutputAfter += 1;
        }
    }

    return std::make_tuple(inputStartIndex, inputEndIndex,
                           inputLinesBefore, inputLinesAfter,
                           outputStartIndex, outputEndIndex,
                           junkOutputBefore, junkOutputAfter);
}

int maximizeOutput(int inputSize, int kernelSize, int stride,
                   const std::tuple<int, int>& pad,
                   const std::tuple<int, int>& output,
                   int maxOutputSliceLines) {
    int outputSize = calcOutputSize(inputSize, kernelSize, stride, pad);

    int outputStartIndex, outputEndIndex;
    std::tie(outputStartIndex, outputEndIndex) = output;

    int _;
    int junkOutputBefore, junkOutputAfter;
    std::tie(_, _, _, _, _, _, junkOutputBefore, junkOutputAfter) =
        inputLinesForOutputLines(inputSize, kernelSize, stride, pad, std::make_tuple(outputStartIndex, outputEndIndex));

    int totalOutputSlice = junkOutputBefore + (outputEndIndex - outputStartIndex) + junkOutputAfter;

    auto isValid = [](int totalOutputSlice, int maxOutputSliceLines, int outputEndIndex, int outputSize) {
        return totalOutputSlice <= maxOutputSliceLines && outputEndIndex <= outputSize;
    };

    int extraLines = 0;
    while (!isValid(totalOutputSlice, maxOutputSliceLines, outputEndIndex + extraLines, outputSize)) {
        extraLines -= 1;

        std::tie(_, _, _, _, _, _, junkOutputBefore, junkOutputAfter) =
            inputLinesForOutputLines(inputSize, kernelSize, stride, pad, std::make_tuple(outputStartIndex, outputEndIndex + extraLines));

        totalOutputSlice = junkOutputBefore + (outputEndIndex + extraLines - outputStartIndex) + junkOutputAfter;
    }

    return outputEndIndex + extraLines + !isValid(totalOutputSlice, maxOutputSliceLines, outputEndIndex, outputSize);
}

}  // namespace

std::vector<TileSoH> heightSolution(int inputSize, int kernelSize, int stride,
                                    const std::tuple<int, int>& pad,
                                    int maxOutputLines) {
    std::vector<TileSoH> heightSol;

    int outputSize = calcOutputSize(inputSize, kernelSize, stride, pad);

    int outputStartIndex = 0;

    while (true) {
        int prevOutputStartIndex = outputStartIndex;
        int outputEndIndex = std::min(outputSize, outputStartIndex + maxOutputLines);

        if (outputEndIndex - outputStartIndex <= 0)
            break;

        int _;
        int inputStartIndex, inputEndIndex;
        int inputLinesBefore, inputLinesAfter;
        int junkOutputBefore, junkOutputAfter;
        std::tie(inputStartIndex, inputEndIndex,
                 inputLinesBefore, inputLinesAfter,
                 _, _,
                 junkOutputBefore, junkOutputAfter) =
            inputLinesForOutputLines(inputSize, kernelSize, stride, pad, std::make_tuple(outputStartIndex, outputEndIndex));

        int newOutputEndIndex = maximizeOutput(inputSize, kernelSize, stride, pad, std::make_tuple(outputStartIndex, outputEndIndex), maxOutputLines);

        // Recompute the (inputStartIndex, inputEndIndex) for the updated newOutputEndIndex
        std::tie(inputStartIndex, inputEndIndex,
                 inputLinesBefore, inputLinesAfter,
                 outputStartIndex, outputEndIndex,
                 junkOutputBefore, junkOutputAfter) =
            inputLinesForOutputLines(inputSize, kernelSize, stride, pad, std::make_tuple(outputStartIndex, newOutputEndIndex));

        heightSol.push_back(std::make_tuple(
            inputLinesBefore + inputEndIndex - inputStartIndex + inputLinesAfter,
            junkOutputBefore + outputEndIndex - outputStartIndex + junkOutputAfter,
            junkOutputBefore,
            junkOutputAfter,
            inputStartIndex - inputLinesBefore,
            inputEndIndex + inputLinesAfter,
            outputStartIndex,
            outputEndIndex));

        outputStartIndex = outputEndIndex;

        if (prevOutputStartIndex == outputStartIndex) {
            // If CMX is very small, it is possible for the output to contain
            // only junk lines. This means that we cannot have progress, therefore
            // we will end up in an infinite loop
            return std::vector<TileSoH>();
        }
    }

    return heightSol;
}

std::vector<TileSoH> heightSolutionWithPooling(int inputSize, int kernelSize, int stride,
                                               int pad,
                                               int maxOutputLines) {
    std::vector<TileSoH> heightSol;

    // This is very specific case for 3x3p1s1 convlution, followed by 2x2s2 pooling with even height
    assert(kernelSize == 3 && stride == 1 && pad == 1);
    assert(inputSize % 2 == 0);

    // For this specific case, the outputSize is:
    int outputSize = inputSize / 2;

    if (outputSize > maxOutputLines) {
        if (maxOutputLines % 2 == 0)
            --maxOutputLines;
    }

    int inputStartIndex = 0;
    int outputStartIndex = 0;

    while (true) {
        int inputEndIndex = std::min(inputStartIndex + 2 * maxOutputLines, inputSize);
        int outputEndIndex = std::min(outputStartIndex + maxOutputLines, outputSize);

        int trueInputNeeded = inputEndIndex - inputStartIndex;
        int outputWithJunk = outputEndIndex - outputStartIndex;
        int junkBefore = outputStartIndex > 0 ?  1 : 0;
        int junkAfter = outputEndIndex < outputSize ? 1 : 0;

        outputStartIndex += junkBefore;
        outputEndIndex -= junkAfter;

        heightSol.push_back(std::make_tuple(
            trueInputNeeded,
            outputWithJunk,
            junkBefore,
            junkAfter,
            inputStartIndex,
            inputEndIndex,
            outputStartIndex,
            outputEndIndex));

        inputStartIndex = inputEndIndex - 4;
        outputStartIndex = outputEndIndex - 1;

        if (outputEndIndex >= outputSize)
            break;
    }

    return heightSol;
}

bool isReluPostOp(const VpuStageHandle& postOp) {
    return (postOp != nullptr && (postOp->type == kRelu || postOp->type == kBiasRelu));
}

size_t HwWeightsWriter::byteSize() const {
    return _hwWeightsDims.totalSize() * sizeof(ie_fp16);
}

void HwWeightsWriter::write(void* dst) const {
    assert(_origWeightsDims.count() == 4);
    assert(_origWeightsDims.totalSize() == _blob->size());

    // taps_hwck_to_cnnhw

    uint32_t KX = _origWeightsDims[Dim::X];
    uint32_t KY = _origWeightsDims[Dim::Y];
    uint32_t IZ = _origWeightsDims[Dim::Z];
    uint32_t OZ = _origWeightsDims[Dim::N];

    uint32_t inputTileDimZ = IZ / _numInputTiles;

    auto srcData = _blob->cbuffer().as<const ie_fp16*>();
    auto dstData = static_cast<ie_fp16*>(dst);

    for (uint32_t oz = 0; oz < OZ; ++oz) {
        uint32_t g = oz / 8;
        uint32_t i = oz % 8;
        for (uint32_t iz = 0; iz < inputTileDimZ; ++iz) {
            for (uint32_t y = 0; y < KY; ++y) {
                for (uint32_t x = 0; x < KX; ++x) {
                    auto srcInd =
                            x +
                            y * KX +
                            (iz + _inputTileInd * inputTileDimZ) * KX * KY +
                            oz * KX * KY * IZ;
                    auto dstInd =
                            i +
                            (y * KX + x) * _hwWeightsDims[Dim::X] +
                            iz * _hwWeightsDims[Dim::X] * _hwWeightsDims[Dim::Y] +
                            g * _hwWeightsDims[Dim::X] * _hwWeightsDims[Dim::Y] * _hwWeightsDims[Dim::Z];

                    assert(srcInd < _origWeightsDims.totalSize());
                    assert(dstInd < _hwWeightsDims.totalSize());

                    auto srcValFp32 = PrecisionUtils::f16tof32(srcData[srcInd]);
                    dstData[dstInd] = PrecisionUtils::f32tof16(srcValFp32 * _scale);
                }
            }
        }
    }
}

size_t ScaledBiasesWriter::byteSize() const {
    return _blob->byteSize();
}

void ScaledBiasesWriter::write(void* dst) const {
    auto srcPtr = _blob->cbuffer().as<const ie_fp16*>();
    auto dstPtr = static_cast<ie_fp16*>(dst);

    for (size_t i = 0; i < _blob->size(); ++i) {
        auto srcValFp32 = PrecisionUtils::f16tof32(srcPtr[i]);
        dstPtr[i] = PrecisionUtils::f32tof16(srcValFp32 * _scale);
    }
}

uint32_t estimateHwBufferSize(const VpuDims& dims) {
    auto strides = calcStrides(dims, VpuDataType::FP16, orderZYX, 16u);
    return dims[Dim::Z] * strides[Dim::Z];
}

namespace {

bool isStageNameInList(const std::vector<std::string>& vec, const std::string& name) {
    return std::find(vec.begin(), vec.end(), name) != vec.end();
}

}  // namespace

void GraphTransformerImpl::addHWStages() {
    auto cmxLimit =
            _blobConfig.useCmxBuffers ?
                std::min(_blobConfig.cmxBufferSize, CMX_BUFFER_SIZE_LIMIT) :
                std::numeric_limits<uint32_t>::max();

    // HACK : detect Yolo network and distinguish original Yolo vs modified

    auto isYoloNetwork =
            _networkName.find("yolo") != std::string::npos ||
            _networkName.find("Yolo") != std::string::npos ||
            _networkName.find("YOLO") != std::string::npos;

    bool isOriginalYolo = false;
    if (isYoloNetwork) {
        CNNLayerPtr fc9Layer;
        for (const auto& layer : _orderedLayers) {
            if (layer->name == "fc9") {
                fc9Layer = layer;
                break;
            }
        }

        if (fc9Layer != nullptr) {
            isOriginalYolo = fc9Layer->type == "FullyConnected";
        }
    }

    for (auto stageIt = _stages.begin(); stageIt != _stages.end(); ++stageIt) {
        auto stage = *stageIt;
        assert(stage != nullptr);

        if (stage->optimized)
            continue;

        if (!_blobConfig.hwWhiteList.empty()) {
            if (!isStageNameInList(_blobConfig.hwWhiteList, stage->name))
                continue;
        }
        if (!_blobConfig.hwBlackList.empty()) {
            if (isStageNameInList(_blobConfig.hwBlackList, stage->name))
                continue;
        }

        if ((stage->type == kConv) || (stage->type == kIm2ColConvolution)) {
            processHWConv(stageIt, cmxLimit, isYoloNetwork, isOriginalYolo);
        } else if (stage->type == kFC) {
            processHWFC(stageIt, isYoloNetwork, isOriginalYolo);
        } else if (stage->type == kMaxPool || stage->type == kAvgPool) {
            processHWPool(stageIt, cmxLimit);
        }
    }
}

GraphTransformerImpl::PostOpInfo GraphTransformerImpl::getPostOpInfoForHW(const VpuStagePtr& mainStage) {
    auto postOp = mainStage->postOp;

    VpuDataHandle biases;
    std::string stageNameSuffix;

    if (postOp == nullptr) {
        // Fake biases
        biases = addNewData(
            newDataId(),
            [](VpuData* data) {
                data->name = "fake";
            });
    } else {
        if (postOp->type == kBias) {
            biases = postOp->inputs[1];
            stageNameSuffix = "+Bias";
        } else if (postOp->type == kRelu) {
            // Fake biases
            biases = addNewData(
                    newDataId(),
                    [](VpuData* data) {
                        data->name = "fake";
                    });
            stageNameSuffix = "+ReLU";
        } else if (postOp->type == kBiasRelu) {
            biases = postOp->inputs[1];
            stageNameSuffix = "+Bias+ReLU";
        } else {
            THROW_IE_EXCEPTION << "[VPU] Unsupported post-op : " << mvTensorOpTypeToStr(postOp->type);
        }
    }

    return std::make_tuple(postOp, biases, std::move(stageNameSuffix));
}
